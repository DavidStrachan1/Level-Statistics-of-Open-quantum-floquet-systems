{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CodeBase import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DSFF = 0, z_k = 10\n",
      "GinUE=0,Poisson=1,Random_louvillian=22\n",
      "Create symmetries in the random Louvillian?0\n",
      "Calculating the Dissipative Spectral Form Factor for the chosen model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    }
   ],
   "source": [
    "class lindbladian_Louville_operator():\n",
    "    def __init__(self,N,h,J,J_prime,delta,delta_prime,b,t,tau,nv,NH,M_choice,\n",
    "                gamma0,gamma_L_plus,gamma_L_min,gamma_R_plus,gamma_R_min,\n",
    "                N_L,g,r,t_min,t_max,s_min,s_max,res,av_num,n):\n",
    "\n",
    "        for local in locals().copy(): \n",
    "            ## equivalent of writing self.gamma = gamma,self.b = b etc.\n",
    "            ## without having to rewrite it.\n",
    "            exec('self.' + local +  ' = locals()[local]')\n",
    "        \n",
    "        self.simulation_choice = int(input('DSFF = 0, z_k = 1'))\n",
    "        \n",
    "        if self.simulation_choice == 0:\n",
    "            self.stat_bool = int(input('GinUE=0,Poisson=1,Random_louvillian=2'))\n",
    "            \n",
    "            if self.stat_bool == 2:\n",
    "                self.sym_bool = int(input('Create symmetries in the random Louvillian?'))\n",
    "            print('Calculating the Dissipative Spectral Form Factor for the chosen model.')    \n",
    "            self.run_DSFF_code()\n",
    "        else:    \n",
    "            \n",
    "            self.model_choice = int(input('Which Model? Deph = 0, Heisenberg XXX = 1, non H XXX = 2,Random Louvillian=3,Next-to-nearest-neighbour-Heisenberg XXZ Hamiltonian=4, no specific model=5'))\n",
    "            \n",
    "            ##setting up random Louvillian\n",
    "            if self.model_choice==3:\n",
    "                self.sym_bool = int(input('Create symmetries in the random Louvillian?'))\n",
    "                self.initialise_Random_Louvillian()\n",
    "            else:\n",
    "                ###initialising variables so they don't have to called in \n",
    "                ###each function\n",
    "                self.proj_bool = int(input('Project onto spin subspace?'))\n",
    "                self.initialise_variables()    \n",
    "            \n",
    "            print(\"Variables initialised,calculating the Louvillian.\")\n",
    "\n",
    "            ##calls function to create the Liouvillian\n",
    "            self.L = self.L(0)#self.Ginibre()\n",
    "\n",
    "            self.evals = (self.L).eigenenergies()\n",
    "            print(\"Calculating P, the time evolution matrix.\")\n",
    "\n",
    "            ##calls function to create P and solve for the eigenenergies.\n",
    "            #self.P,self.evals = self.P()\n",
    "\n",
    "            ##calls function to create z_k along with the degeneracy factor of each ratio\n",
    "            self.deg_factor = np.unique(self.evals,return_counts=True)[-1]\n",
    "            deg_bool = int(input('Remove degeneracy?'))\n",
    "            if deg_bool:\n",
    "\n",
    "                self.E_array,self.deg_factor = np.unique(self.evals,return_counts=True)\n",
    "            else:   \n",
    "\n",
    "                ##defining E_array for z_k_spec and for the parallelization\n",
    "                self.E_array = self.evals#np.unique(self.evals)\n",
    "\n",
    "            \"\"\"Currently using the non-parallelised z_k function.\"\"\"\n",
    "            #self.z_k = parallelise_job(self.z_k_spec,self.E_array,verbose = False)\n",
    "            self.z_k = self.z_k(self.E_array)\n",
    "\n",
    "\n",
    "\n",
    "            ##choice of whether to save data\n",
    "            self.save_boolean = bool(int(input('Save Data?')))\n",
    "            self.add_to_average = int(input('Add to average?'))\n",
    "\n",
    "            ##defines path for my computer\n",
    "            self.path = 'C://Users/david/OneDrive/Documents/UNI/UCL project/data/'  \n",
    "\n",
    "            ##retrieves the single number signatures of the data and prints them.\n",
    "            self.mean_r, self.mean_cos, self.mean_theta = self.single_number_signatures(self.z_k)\n",
    "\n",
    "\n",
    "            ##list of all parameters needed\n",
    "            data_list = ['mean_r='+str(self.mean_r),\n",
    "                         'mean_cos='+str(self.mean_cos),\n",
    "                         'mean_theta='+str(self.mean_theta),\n",
    "                         'N='+str(self.N),'h='+str(self.h),\n",
    "                         'J='+str(self.J),'J_prime='+str(self.J_prime),\n",
    "                         'delta='+str(self.delta),\n",
    "                         'delta_prime='+str(self.delta),'b='+str(self.b),\n",
    "                         't='+str(self.t),'tau='+str(self.tau),\n",
    "                         'nv='+str(self.nv),'gamma0='+str(self.gamma0),\n",
    "                         'gamma_L_plus='+str(self.gamma_L_plus),\n",
    "                         'gamma_L_min='+str(self.gamma_L_min),\n",
    "                         'gamma_R_plus='+str(self.gamma_R_plus),\n",
    "                         'gamma_R_min='+str(self.gamma_R_min)]\n",
    "            ##as array\n",
    "            data_array = np.asarray((self.mean_r,self.mean_cos,\n",
    "                         self.mean_theta,self.N,self.h,\n",
    "                         self.J,self.J_prime,self.delta,self.delta_prime,\n",
    "                         self.b,self.t,self.tau,\n",
    "                         self.nv,self.gamma0,self.gamma_L_plus,\n",
    "                         self.gamma_L_min,self.gamma_R_plus,\n",
    "                         self.gamma_R_min))\n",
    "\n",
    "            if self.proj_bool:\n",
    "                data_list = np.append('M = '+str(self.M_choice),data_list)\n",
    "                data_array = np.append('M = '+str(self.M_choice),data_array)\n",
    "\n",
    "\n",
    "\n",
    "            if self.save_boolean:\n",
    "                ##sorting names\n",
    "                list_name = 'list, N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "                array_name = 'array, N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "\n",
    "\n",
    "                ##sorting paths \n",
    "                self.SNS_path = self.path +'Single Number Signatures/'\n",
    "                self.z_k_path =self.path + 'z_k raw data/'\n",
    "\n",
    "\n",
    "                ##Sorting where to save the data\n",
    "                self.z_k_path_final = self.z_k_path\n",
    "                ##Deph model\n",
    "                if self.model_choice==0:\n",
    "                    self.z_k_path_final = self.z_k_path+'Deph/'\n",
    "                    self.SNS_path = self.SNS_path+'Deph/'\n",
    "\n",
    "                    ##needed for add_to_average function\n",
    "                    average_path_add_on = ', Deph average.npy'\n",
    "\n",
    "                ##Heisenberg model\n",
    "                if self.model_choice==1:\n",
    "                    self.z_k_path_final = self.z_k_path+'Heisenberg XXX/'\n",
    "                    self.SNS_path = self.SNS_path+'Heisenberg XXX/'\n",
    "\n",
    "                    ##needed for add_to_average function\n",
    "                    average_path_add_on = ', Heisenberg XXX average.npy'\n",
    "\n",
    "                ##non-Heisenberg XXX model\n",
    "                if self.model_choice==2:\n",
    "                    self.z_k_path_final = self.z_k_path+'non H XXX/'\n",
    "                    self.SNS_path = self.SNS_path+'non H XXX/'\n",
    "\n",
    "                    ##needed for add_to_average function\n",
    "                    average_path_add_on = ', non H XXX average.npy'\n",
    "\n",
    "\n",
    "                if not os.path.isdir(self.z_k_path):\n",
    "                    os.mkdir(self.z_k_path)\n",
    "                if not os.path.isdir(self.SNS_path):\n",
    "                    os.mkdir(self.SNS_path)\n",
    "\n",
    "                self.list_path = self.SNS_path+list_name\n",
    "                self.array_path = self.SNS_path+array_name\n",
    "\n",
    "\n",
    "                if self.add_to_average:\n",
    "                    ##calls function to average data with all previous relevant simulations \n",
    "                    self.averaging_data(self.z_k_path,data_list=data_list,average_path_add_on=average_path_add_on)\n",
    "\n",
    "                ##pathways for graphs\n",
    "\n",
    "                self.label_add_on = ', N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "                if self.proj_bool:\n",
    "                    self.label_add_on = 'M= '+str(self.M_choice) +self.label_add_on\n",
    "                self.graph_path_r = self.z_k_path_final+'r barchart ,'+self.label_add_on\n",
    "                self.graph_path_theta = self.z_k_path_final+'theta barchart ,'+self.label_add_on\n",
    "                self.heatmap_path = self.z_k_path_final+'heatmap,'+self.label_add_on\n",
    "                self.z_k_path_final = self.z_k_path_final+'z_k,'+self.label_add_on\n",
    "\n",
    "\n",
    "                np.save(self.z_k_path_final+'.npy',self.z_k)\n",
    "                np.save(self.list_path+'.npy',data_list)\n",
    "                np.save(self.array_path+'.npy',data_array)\n",
    "\n",
    "            ##plots data\n",
    "            self.heatmap(self.z_k,self.deg_factor)\n",
    "            print('mean r value = '+ str(self.mean_r))\n",
    "            print('mean cos(theta) = '+str(self.mean_cos))\n",
    "            print('mean theta = '+str(self.mean_theta))\n",
    "        \n",
    "    def averaging_data(self,path,data_list,average_path_add_on):\n",
    "        \"\"\"\n",
    "        Adds the newly simulated data to the data set of all previous simulations with appropriate\n",
    "        weighting for averaging.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        ##if the average has not been done before, the file must first be created\n",
    "        trig = int(input('First time inputing data for the average of this model?'))\n",
    "        if trig:\n",
    "                ##creates a list of size 3, with the inputs being\n",
    "                ##the data, the number of datasets added and the parameters (data_list) respectively.\n",
    "                z_k_av = [self.z_k,1,data_list]\n",
    "                np.save(path+'N=' + str(self.N) +' , b=' +str(self.b)+average_path_add_on, z_k_av)                 \n",
    "        else:\n",
    "            ##loading the average of previous simulations\n",
    "            z_k_av = np.load(path+'N=' + str(self.N) +' , b=' +str(self.b)+average_path_add_on,\n",
    "                            allow_pickle=True)\n",
    "            ##checking to see if they both have the same parameters\n",
    "            if data_list != z_k_av[-1]:\n",
    "                raise AttributeError('Trying to add two sets of data with different parameters')\n",
    "            else:\n",
    "                ##adding to the average data mathematically.\n",
    "                z_k_av_updated = []\n",
    "                z_k_av_updated.append((z_k_av[1]*z_k_av[0] + self.z_k)/(z_k_av[1]+1))\n",
    "                z_k_av_updated.append(z_k_av[1]+1)\n",
    "                z_k_av_updated.append(data_list)\n",
    "\n",
    "                np.save(path+'N=' + str(self.N) +' , b=' +str(self.b)+average_path_add_on, z_k_av_updated)\n",
    "    \n",
    "    \n",
    "    def initialise_Random_Louvillian(self,):\n",
    "        \"\"\"Sets up the variables so the function L will give a \n",
    "        Beta =2 Random Louvillian as defined by the paper.\"\"\"\n",
    "        n=self.N_L**2\n",
    "        \n",
    "        self.proj_bool = 0\n",
    "        \n",
    "        ##supposing we have an array of numbers which gives the \n",
    "        ##dimensions of the blocks, the following with create this block \n",
    "        ##diagonal matrix.\n",
    "        array = np.asarray([n/2,n/2])\n",
    "        if self.sym_bool:\n",
    "            self.H1 = np.zeros((np.product(array),np.product(array)))\n",
    "            for i in range(np.size(array)):\n",
    "                Gaus = Qobj(np.random.normal(scale=1/np.sqrt(2*n),size=(array[i],array[i])) + 1j*np.random.normal(scale=1/np.sqrt(2*n),size=(array[i],array[i])))\n",
    "                \n",
    "                ##OR\n",
    "                ##not sure what the variance should be for the sub matrices (blocks), should it be 1/array[i] or 1/n\n",
    "                \n",
    "                Gaus = Qobj(np.random.normal(scale=1/np.sqrt(2*array[i]),size=(array[i],array[i])) + 1j*np.random.normal(scale=1/np.sqrt(2*array[i]),size=(array[i],array[i])))\n",
    "                \n",
    "                \n",
    "                \n",
    "                sub_H1 = ((Gaus + Gaus.dag())/2)\n",
    "                start_idx = np.sum(array[:i])-array[i]\n",
    "                end_idx = np.sum(array[:i])\n",
    "                self.H1[start_idx:end_idx,start_idx:end_idx]=sub_H1\n",
    "        if not self.sym_bool:\n",
    "            Gaus = Qobj(np.random.normal(scale=1/np.sqrt(2*n),size=(n,n)) + 1j*np.random.normal(scale=1/np.sqrt(2*n),size=(n,n)))\n",
    "            self.H1 = ((Gaus + Gaus.dag())/np.sqrt(2))        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.W_list = []\n",
    "        \n",
    "        for i in range(self.r):\n",
    "                W = self.g*Qobj(np.random.normal(scale=1/np.sqrt(2*n),size=(n,n)) + 1j*np.random.normal(scale=1/np.sqrt(2*n),size=(n,n)))\n",
    "                self.W_list.append(W)\n",
    "        self.identity = qeye(n)\n",
    "        \"\"\"\n",
    "        The jump operators should be traceless, but I don't know if they are\n",
    "        by construction.\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "\n",
    "    def initialise_variables(self,):\n",
    "        \"\"\"\n",
    "        Defines all generic variables that are needed for the simulation.\n",
    "        \"\"\"\n",
    "\n",
    "        ####gamma is an array of 5 constants that control the dissipation \n",
    "\n",
    "        si = qeye(2) #identity for a spin-1/2 particle\n",
    "        sz = sigmaz() ## z pauli matrix\n",
    "        sx = sigmax() ## y pauli matrix\n",
    "        sy = sigmay() ## y pauli matrix\n",
    "        sigp = sigmap() ##plus ladder operator for spin 1/2\n",
    "        sigm = sigmam() ##minus ladder operator for spin 1/2\n",
    "        self.sz_list = []\n",
    "        sx_list = []\n",
    "        sy_list = []\n",
    "        sigp_list = []\n",
    "        sigm_list = []\n",
    "        h_arr = np.random.uniform(-self.h,self.h,self.N) ##random uniform distribution from -h to h\n",
    "\n",
    "        for n in range(self.N):\n",
    "            op_list = []\n",
    "            for m in range(self.N):\n",
    "                op_list.append(si) ##creates a list of identity operators for each particle\n",
    "            self.identity = tensor(op_list) ##creates an identity over the 2^N x 2^N space\n",
    "            \n",
    "            \n",
    "            op_list[n] = sz\n",
    "            self.sz_list.append(tensor(op_list))\n",
    "\n",
    "            op_list[n] = sx\n",
    "            sx_list.append(tensor(op_list))\n",
    "            \n",
    "            op_list[n] = sy\n",
    "            sy_list.append(tensor(op_list))\n",
    "            \n",
    "            if n==0:\n",
    "                op_list[n] = sigp\n",
    "                sigp_list.append(tensor(op_list))\n",
    "\n",
    "                op_list[n] = sigm\n",
    "                sigm_list.append(tensor(op_list))\n",
    "            if n==self.N-1:\n",
    "                op_list[n] = sigp\n",
    "                sigp_list.append(tensor(op_list))\n",
    "\n",
    "                op_list[n] = sigm\n",
    "                sigm_list.append(tensor(op_list))\n",
    "\n",
    "        \n",
    "        if self.proj_bool:\n",
    "            self.S_z_tot = sum(self.sz_list)\n",
    "            self.S_z_super = tensor(self.S_z_tot,self.identity) - tensor(self.identity,self.S_z_tot.trans())\n",
    "\n",
    "            ##M_indices gives the columns/rows of the matrix representation of the basis\n",
    "            ##that have M=M_choice\n",
    "            \"\"\"Note that the eigenvalues of S_z_super are given by 2(N-M) rather than (N-M). This is because when \n",
    "            a spin is flipped the change in eigenvalue is 2 (in this representation |s_l|=1, not 1/2)\"\"\"\n",
    "            self.M_indices = np.where(self.S_z_super.diag()==(2*self.N-2*self.M_choice))[0]\n",
    "\n",
    "            ##list of dummy indices for parallelisation\n",
    "            self.y = range(len(self.M_indices))\n",
    "\n",
    "            ##inputs for parallelisation of projection\n",
    "            \"\"\"This creates an array of shape (N_m*N_m,2) where N_m is the dimension of the subspace. The first entry is \n",
    "            the M index, and the second is a dummy index for labelling (ordering after parallelisation).\"\"\"\n",
    "            #self.inputs = [(self.M_indices[i],self.M_indices[j],self.y[i],self.y[j]) for i in range(len(self.y)) for j in range(len(self.y))]\n",
    "            self.inputs = [(self.M_indices[i],self.y[i]) for i in range(len(self.y))]\n",
    "\n",
    "            ##defines the dimension of the M spin subspace\n",
    "            self.dim_M = np.size(self.M_indices)\n",
    "            if self.dim_M != ss.comb(2*self.N,self.M_choice):\n",
    "                raise AttributeError('Size of matrix is not 2N choose M') \n",
    "\n",
    "        ## construct the hamiltonian \n",
    "        H_S = 0\n",
    "        self.Hk = 0\n",
    "        ## bulk dephasing\n",
    "        W_list = [] ##list of jump operators\n",
    "\n",
    "        # energy splitting terms\n",
    "        for n in range(self.N):\n",
    "            \n",
    "            ##random field term\n",
    "            H_S += h_arr[n] * self.sz_list[n]\n",
    "            ##bulk dephasing\n",
    "            W_list.append(np.sqrt(self.gamma0) * self.sz_list[n])\n",
    "            ##kicking term\n",
    "            self.Hk += self.b * sx_list[n]\n",
    "            \n",
    "\n",
    "        # interaction terms\n",
    "        for n in range(self.N-1): \n",
    "            H_S += self.J * self.delta * self.sz_list[n] * self.sz_list[n+1]\n",
    "            H_S += self.J * sx_list[n] * sx_list[n+1]\n",
    "            H_S += self.J * sy_list[n] * sy_list[n+1]\n",
    "        \n",
    "        \n",
    "        if self.model_choice == 4:\n",
    "            for n in range(self.N-2): \n",
    "                H_S += self.J_prime * self.delta_prime * self.sz_list[n] * self.sz_list[n+2]\n",
    "                H_S += self.J_prime * sx_list[n] * sx_list[n+2]\n",
    "                H_S += self.J_prime * sy_list[n] * sy_list[n+2]\n",
    "                \n",
    "        self.H1 =H_S\n",
    "        self.dim_H = self.H1.shape[0]\n",
    "\n",
    "        ##amplitude damping\n",
    "        W_list.append(np.sqrt(self.gamma_L_plus)*sigp_list[0]) ##W_{N+1}\n",
    "        W_list.append(np.sqrt(self.gamma_L_min)*sigm_list[0]) ##W_{N+2}\n",
    "        W_list.append(np.sqrt(self.gamma_R_plus)*sigp_list[1]) ##W_{N+3}\n",
    "        W_list.append(np.sqrt(self.gamma_R_min)*sigm_list[1]) ##W_{N+4}\n",
    "        \n",
    "        self.W_list = W_list\n",
    "        self.sigp_list = sigp_list\n",
    "        self.sigm_list = sigm_list\n",
    "\n",
    "    \n",
    "    def spin_proj(self,matrix,M_choice):\n",
    "        \"\"\"\n",
    "        Takes a matrix in the whole hilbert space and projects to the M_choice subspace.\n",
    "        This function is inefficient as the whole matrix has to be calculated as an input, \n",
    "        this function isn't being currently used.\n",
    "        \"\"\"\n",
    "\n",
    "        #This gives the rows/columns (eigenstates) that have don't have M=M_choice\n",
    "        M_choice_indices = np.where(self.S_z_super.diag()!=M_choice)[0]\n",
    "        for i in range(np.size(M_choice_indices)):\n",
    "            ##np.delete is used to remove the rows and columns that correspond to \n",
    "            ##eigenstates that don't have the desired spin state.\n",
    "            ## the -i factor accounts for the fact that each iteration a row and column\n",
    "            ##is removed, decreasing the index by 1 each time.\n",
    "            matrix = np.delete(arr=matrix,obj=M_choice_indices[i]-i,axis=0)\n",
    "            \n",
    "            #deletes the ith column\n",
    "            matrix = np.delete(arr=matrix,obj=M_choice_indices[i]-i,axis=1)\n",
    "        return matrix\n",
    " \n",
    "    def Ginibre(self,):\n",
    "        \n",
    "        real = np.random.normal(scale=1,size=(256,256))\n",
    "        imag = 1j * np.random.normal(scale=1,size=(256,256))\n",
    "        Ginibre = real + imag\n",
    "        return Qobj(Ginibre)\n",
    "    \n",
    "    \n",
    "    def L(self,i):\n",
    "        \"\"\"\n",
    "        creates L from the definition of its matrix representation, \n",
    "        equation 4.1 of the notes currently. \n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        W_term = 0 \n",
    "        ###calculates sum_{\\mu}(W_{\\mu}^{\\dag}*W_{\\mu})\n",
    "        for i in range(len(self.W_list)):\n",
    "            W_term += (self.W_list[i].dag())*self.W_list[i]\n",
    "               \n",
    "        H_left = self.H1 - (1j/2)*W_term\n",
    "        H_right = self.H1 + (1j/2)*W_term\n",
    "\n",
    "        H_cross_term = 0\n",
    "        ##calculates  sum_{\\mu}(W_{\\mu}\\otimes W_{\\mu}^{\\dag})\n",
    "        for i in range(len(self.W_list)):\n",
    "            if self.proj_bool:\n",
    "                self.A = self.W_list[i]\n",
    "                self.dim_A = self.A.shape[0]\n",
    "                self.B = self.W_list[i].conj()\n",
    "                #H_cross_term += self.projection(self.M_indices)\n",
    "\n",
    "                outputs = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "                \n",
    "                output = np.column_stack([outputs[j] for j in self.y])\n",
    "                H_cross_term += output\n",
    "            else:\n",
    "                H_cross_term += tensor(self.W_list[i],self.W_list[i].conj())\n",
    "                \n",
    "        if self.proj_bool:\n",
    "            self.A = H_left\n",
    "            self.B = self.identity\n",
    "            outputs = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "            L = -1j*np.column_stack([outputs[i] for i in self.y])\n",
    "            \n",
    "            self.A = self.identity\n",
    "            self.B = H_right.trans()\n",
    "            outputs = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "            L += 1j*np.column_stack([outputs[j] for j in self.y])\n",
    "        else:\n",
    "            L = -1j*tensor(H_left,self.identity)\n",
    "            L += 1j*tensor(self.identity,H_right.trans())\n",
    "            \n",
    "        \n",
    "        L += H_cross_term\n",
    "        \n",
    "        return Qobj(L)\n",
    "    \n",
    "    def P(self,):\n",
    "        \n",
    "        if self.t>(self.tau/2):\n",
    "            ##defining the commutator kicking superoperator\n",
    "            if self.proj_bool:\n",
    "                self.A = self.Hk\n",
    "                self.dim_A = self.A.shape[0]\n",
    "                self.B = self.identity\n",
    "                HK_commute_SO = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "                HK_commute_SO = -1j*np.column_stack([outputs[j] for j in self.y])\n",
    "\n",
    "                self.A = self.identity\n",
    "                self.B = self.Hk.trans()\n",
    "                output = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "                output = 1j*np.column_stack([outputs[j] for j in self.y])\n",
    "                HK_commute_SO += output\n",
    "            else:\n",
    "                HK_commute_SO = -1j*tensor(self.Hk,self.identity)\n",
    "                HK_commute_SO += 1j*tensor(self.identity,self.Hk.trans())\n",
    "                HK_commute_SO = Qobj(spin_proj(matrix = HK_commute_SO, M_choice=self.M_choice))\n",
    "            \n",
    "        \n",
    "        ###exponentiates the matrices and calculates P\n",
    "            expH = Qobj(HK_commute_SO).expm()\n",
    "            exp1 = (self.L*self.tau/2).expm()\n",
    "            exp2 = (self.L*(self.t-self.tau/2)).expm()\n",
    "            P = exp2*(expH*exp1)\n",
    "        if self.t<=self.tau/2:\n",
    "            P = (self.L*self.t).expm()\n",
    "        \n",
    "        evals = P.eigenenergies()\n",
    "       \n",
    "        \n",
    "\n",
    "        return P,evals\n",
    "    \n",
    "    def projection(self,A,B,M_indices):\n",
    "        \"\"\"\n",
    "        Calculates the columns of the whole matrix representation that give the \n",
    "        desired subspace. This is the unparallelised version, which \n",
    "        isn't currently being used.\n",
    "         The loop takes the the column/row indices and calculates what element they correspond to in\n",
    "         the Kronecker product of A cross B. For explanation of the R, K terms see the latex notes.\n",
    "        \"\"\"\n",
    "\n",
    "        ##M_indices is the list of rows/columns of\n",
    "        ##the whole space matrix representation that\n",
    "        ##have the quantum number M\n",
    "\n",
    "        ##A and B are matrices that have dimensions of 2^N by 2^N\n",
    "\n",
    "        dim_M = np.size(M_indices)\n",
    "        dim_A = A.shape[0]\n",
    "        ##out is a matrix of zeros that has dimensions of the subspace.\n",
    "        out = np.zeros((dim_M,dim_M),dtype=np.complex64)\n",
    "        n=-1\n",
    "        for i in tqdm_notebook(M_indices,leave=False):\n",
    "            m = 0\n",
    "            n += 1\n",
    "            for j in M_indices:\n",
    "                R_i = np.floor(i/dim_A)\n",
    "                R_j = np.floor(j/dim_A)\n",
    "                K_i = i -dim_A*R_i\n",
    "                K_j = j -dim_A*R_j\n",
    "                #print(R_j)\n",
    "                #print(M_indices[-1])\n",
    "                #print(np.max(np.array((R_i,R_j,K_i,K_j))))\n",
    "                A_cross_B_ij = A[R_i,R_j]*B[K_i,K_j]\n",
    "                out[n,m] = A_cross_B_ij\n",
    "                m +=1\n",
    "        return Qobj(out)\n",
    "    \n",
    "    def para_projection(self,M_index_y):\n",
    "        \"\"\"\n",
    "        Parallelised version of the projection function.\n",
    "        \"\"\"\n",
    "        ##y is a list of dummy indices needed to recover the \n",
    "        ##order after parallelisation\n",
    "        M_index,y = M_index_y\n",
    "        \n",
    "\n",
    "        ##M_indices is the list of rows/columns of\n",
    "        ##the whole space matrix representation that\n",
    "        ##have the quantum number M\n",
    "\n",
    "        ##A and B are matrices that have dimensions of 2^N by 2^N\n",
    "\n",
    "        ##out is a matrix of zeros that has dimensions of the subspace.\n",
    "        out = np.zeros(self.dim_M,dtype=np.complex64)\n",
    "        m=0\n",
    "        R_i = np.floor(M_index/self.dim_A)\n",
    "        K_i = M_index -self.dim_A*R_i\n",
    "        for j in self.M_indices:\n",
    "            R_j = np.floor(j/self.dim_A)\n",
    "            K_j = j -self.dim_A*R_j\n",
    "            A_cross_B_ij = self.A[R_i,R_j]*self.B[K_i,K_j]\n",
    "            out[m] = A_cross_B_ij\n",
    "            m +=1\n",
    "        return y, Qobj(out)\n",
    "    \n",
    "    \n",
    "    def GinUE_or_Pois(self,i):\n",
    "        \"\"\"n by n is the size of the GinUE matrix\"\"\"\n",
    "        \"\"\"array of which the DSFF is calculated.\"\"\"\n",
    "        #The elements of a GinUE matrix are (2D) gaussian distributed\n",
    "        #with 1/N variance\n",
    "        if self.stat_bool==0:\n",
    "            GinUE = Qobj(np.random.normal(scale=1/np.sqrt(self.n),size=(self.n,self.n)) +1j*np.random.normal(scale=1/np.sqrt(self.n),size=(self.n,self.n)))\n",
    "            z = GinUE.eigenenergies()\n",
    "            #z = z/np.sqrt(self.n)\n",
    "        #Poisson\n",
    "        if self.stat_bool==1:\n",
    "            z= np.random.normal(scale=1,size=(self.n)) +1j*np.random.normal(scale=1,size=(self.n))\n",
    "            \n",
    "        \"\"\"calls DSFF function to retrieve variables, see DSFF code for definitions.\"\"\"\n",
    "        return self.DSFF(z,self.t,self.s)[0]\n",
    "    \n",
    "    def run_Louv(self,i):\n",
    "        self.initialise_Random_Louvillian()\n",
    "        L = self.L(0)\n",
    "        z = 10*(L).eigenenergies()\n",
    "        return self.DSFF(z,self.t,self.s)[0]\n",
    "    \n",
    "    def run_DSFF_code(self,):\n",
    "    \n",
    "        \"\"\"t_min,t_max,s_min,s_max and res\n",
    "        set up grid for t and s variables.\n",
    "        av_num is the number of random matrices sampled.\"\"\"\n",
    "        \n",
    "        \n",
    "        self.t= np.linspace(self.t_min,self.t_max,self.res)\n",
    "        self.s = np.linspace(self.s_min,self.s_max,self.res)\n",
    "        \n",
    "        \"\"\"does the same as for x_n and y_m etc but for the time variables.\"\"\"\n",
    "        t_n, s_n = self.t.reshape(-1,1), self.s.reshape(-1,1)\n",
    "        t_n, s_n = t_n.repeat(self.res,1),s_n.repeat(self.res,1)\n",
    "        t_m, s_m = t_n.transpose(), s_n.transpose()\n",
    "\n",
    "        \"\"\"the elements of tau_matrix give all the points \n",
    "        in the t,s (complex) grid.\"\"\"\n",
    "        self.tau_matrix = 1j*s_m +t_n \n",
    "\n",
    "        out = 0\n",
    "        if self.stat_bool != 2:\n",
    "            o = parallelise_job(self.GinUE_or_Pois,range(self.av_num),verbose = True,n_jobs = -1)\n",
    "        if self.stat_bool == 2:\n",
    "            o = parallelise_job(self.run_Louv,range(self.av_num),verbose = True,n_jobs = -1)\n",
    "            \n",
    "        for _ in o:\n",
    "            out += _\n",
    "\n",
    "        DSFF_ = out/(self.av_num+1)\n",
    "        tau_mag = np.abs(self.tau_matrix).flatten(order='C')\n",
    "        DSFF_ = np.abs(DSFF_).flatten(order='C')\n",
    "\n",
    "\n",
    "        path = 'C://Users/david/OneDrive/Documents/UNI/UCL project/data/'\n",
    "        save = int(input(\"save graph?\"))\n",
    "        \n",
    "        plt.plot(tau_mag,DSFF_)\n",
    "        plt.grid()\n",
    "        plt.xlabel('tau')\n",
    "        plt.ylabel('DSFF')\n",
    "        plt.title('DSFF against tau ')\n",
    "        if save:\n",
    "            path_add_on = input('Name of DSFF graph?')\n",
    "            path = path+ str(path_add_on)\n",
    "            plt.gcf().tight_layout()        \n",
    "            plt.savefig(path+'.png',dpi=250)\n",
    "        #plt.ylim(0,500)\n",
    "        plt.show()\n",
    "        \n",
    "        if self.stat_bool==0:\n",
    "            GinUE = Qobj(np.random.normal(scale=1/np.sqrt(2*self.n),size=(self.n,self.n)) +1j*np.random.normal(scale=1/np.sqrt(2*self.n),size=(self.n,self.n)))\n",
    "            z = GinUE.eigenenergies()\n",
    "            \n",
    "        if self.stat_bool==1:\n",
    "            z= np.random.normal(scale=1/np.sqrt(2),size=(self.n)) + 1j*np.random.normal(scale=1/np.sqrt(2),size=(self.n))\n",
    "        if self.stat_bool==2:\n",
    "            self.initialise_Random_Louvillian()\n",
    "            L = self.L(0)\n",
    "            print(np.shape(L))\n",
    "            z = (L).eigenenergies()\n",
    "            self.factor = 2*self.N_L*np.sqrt(2*self.r)*self.g*self.g#np.sqrt(2*self.r)*self.g*self.g*2*self.N_L\n",
    "            z = z/self.factor\n",
    "        \n",
    "        \n",
    "        x = (z).real\n",
    "        y = (z).imag\n",
    "        \n",
    "        plt.scatter(x,y)\n",
    "        plt.grid()\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('scatter plot of the eigenstates')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    '''''''''''''''''Level Statistics functions'''''''''''''''''\n",
    "    def z_k(self,E_array):\n",
    "        z_k = [] ##setting up ratio array\n",
    "        \n",
    "        \n",
    "        for i in tqdm_notebook(range(np.size(E_array)),leave=False):\n",
    "                \n",
    "            ##creating an array of the indices of the ratios ascending in magnitude from \n",
    "            ##the ith ratio\n",
    "            \n",
    "            E_idx_sorted = np.argsort(np.abs(E_array-E_array[i]))\n",
    "            \n",
    "            ##takes the first one\n",
    "            NN = E_array[E_idx_sorted[1]] \n",
    "            diff1 = NN-E_array[i]\n",
    "            ##takes the second one\n",
    "            NNN = E_array[E_idx_sorted[2]] \n",
    "            diff2 = NNN-E_array[i]\n",
    "            \n",
    "            ##definition of z_k\n",
    "            z_k.append(np.nan_to_num(diff1/diff2))\n",
    "        z_k = np.asarray(z_k) \n",
    "        return z_k\n",
    "    \n",
    "    \n",
    "    def z_k_spec(self,val):\n",
    "        \n",
    "      \n",
    "        ##creating an array of the indices of the ratios ascending in magnitude from \n",
    "        ##the ith ratio\n",
    "        E_idx_sorted = np.argsort(np.abs(self.E_array-val))\n",
    "\n",
    "        ##takes the first one\n",
    "        NN = self.E_array[E_idx_sorted[1]] \n",
    "        diff1 = NN-val\n",
    "        ##takes the second one\n",
    "        NNN = self.E_array[E_idx_sorted[2]] \n",
    "        diff2 = NNN-val\n",
    "\n",
    "        ##definition of z_k\n",
    "        z_k_spec = np.nan_to_num(diff1/diff2)\n",
    "        \n",
    "        return z_k_spec\n",
    "\n",
    "    \n",
    "    def DSFF(self,z,t,s):\n",
    "        \"\"\"this function calculates the Dissipative Spectral Form Factor\n",
    "        as defined in the paper 'Spectral statistics of non-Hermitian matrices and \n",
    "        dissipative quantum chaos'.\"\"\"\n",
    "\n",
    "\n",
    "        \"\"\"sets up the real and imaginary part of the spectrum in order to caclulate the DSFF.\"\"\"\n",
    "        x = np.real(z)\n",
    "        y = np.imag(z)\n",
    "        dim_ = np.size(x)\n",
    "\n",
    "        \"\"\"the following casts x and y only 2D arrays, with the x_n and x_m etc\n",
    "        are aligned along opposite axes. These are used to create a 2D array\n",
    "        of all combination of x_n-x_m (y_n-y_m) which are all the entries of x_mn (y_mn).\"\"\"\n",
    "        x_n, y_n = x.reshape(-1,1), y.reshape(-1,1)\n",
    "        x_n, y_n = x_n.repeat(dim_,1),y_n.repeat(dim_,1)\n",
    "        x_m, y_m = x_n.transpose(), y_n.transpose()\n",
    "        x_mn, y_mn = x_n - x_m, y_n - y_m ##could be other way round\n",
    "\n",
    "        \"\"\"creates the 2D (ie complex) z_mn matrix.\"\"\"\n",
    "        z_mn = x_mn +1j*y_mn\n",
    "\n",
    "        \"\"\"Calculates the DSFF for all tau coordinates as a grid.\"\"\"\n",
    "        DSFF = np.zeros((self.res,self.res),dtype=np.complex64)\n",
    "        for i in tqdm_notebook(range(self.res),leave=False):\n",
    "            for j in range(self.res):\n",
    "                K_matrix = np.exp(1j*(x_mn*self.tau_matrix[i,j].real +y_mn*self.tau_matrix[i,j].imag))\n",
    "                DSFF[i,j] = np.sum(K_matrix)\n",
    "\n",
    "        return DSFF, z_mn\n",
    "    \n",
    "    \n",
    "    \n",
    "    def heatmap(self,z_k,deg_factor):\n",
    "        print('Setting up plots')\n",
    "        \n",
    "        ##creating grid in complex space\n",
    "        \"\"\"\n",
    "        To ensure there is an (0,0) point in both real_vals and imag_vals,\n",
    "        self.nv must be odd\n",
    "        \"\"\"\n",
    "        real_vals = np.linspace(-1,1,self.nv)\n",
    "        imag_vals = 1j*np.linspace(-1,1,self.nv)\n",
    "        \n",
    "        ##creating empty 2D array for heatmap values\n",
    "        \n",
    "        heatmap_vals = np.zeros((self.nv,self.nv))\n",
    "        \n",
    "        ##resolution of grid\n",
    "        delta = (np.max(real_vals)-np.min(real_vals))/np.size(real_vals)\n",
    "        \n",
    "        for i in tqdm_notebook(range(self.nv-1),leave=False):\n",
    "            for j in range(self.nv-1):\n",
    "                \n",
    "                ##creates booleans in order to get rid of any values\n",
    "                ##that don't lie in the ith,jth square of the grid\n",
    "                real_bool =(z_k.real>=real_vals[i])*(z_k.real<=real_vals[i+1]) \n",
    "                imag_bool =(z_k.imag>=(imag_vals[j].imag))*(z_k.imag<=(imag_vals[j+1].imag))\n",
    "    \n",
    "                ##summing up how many non-zero values there are,\n",
    "                ##which is then multiplied by the degeneracy factor of each distinct eigenenergy.\n",
    "                \n",
    "                heatmap_vals[j,i] =  np.sum(real_bool*imag_bool)##python indices are opposite to matrix convention\n",
    "                \n",
    "                \n",
    "        ##self.NH defines the number of histograms\n",
    "        theta_array = np.linspace(-np.pi,np.pi,self.NH)\n",
    "        r_array = np.linspace(0,1,self.NH)\n",
    "        theta_hists = np.zeros(self.NH)\n",
    "        r_hists = np.zeros(self.NH)\n",
    "        \n",
    "        r_vals = np.abs(z_k)\n",
    "        theta_vals = np.angle(z_k)\n",
    "        \n",
    "        ##creates a 1D array of the heatmap values\n",
    "        flattened_vals = heatmap_vals.flatten()\n",
    "        \n",
    "        ###flattens theta values into a 1D array.\n",
    "        flattened_theta_vals = theta_vals.flatten()\n",
    "        \n",
    "        ###flattens r values into a 1D array.\n",
    "        flattened_r_vals = r_vals.flatten()\n",
    "        \n",
    "        for i in range(self.NH-1):\n",
    "            r_bool =(flattened_r_vals>=r_array[i])*(flattened_r_vals<=r_array[i+1]) \n",
    "            theta_bool =(flattened_theta_vals>=theta_array[i])*(flattened_theta_vals<=theta_array[i+1])\n",
    "            r_hists[i] = np.sum(r_bool)/np.size(z_k)\n",
    "            theta_hists[i] = np.sum(theta_bool)/np.size(z_k)\n",
    "        \n",
    "        \n",
    "        ##making the local variables global (just so debugging is easier)\n",
    "        self.r_array = r_array\n",
    "        self.r_hists = r_hists\n",
    "        self.theta_array = theta_array\n",
    "        self.theta_hists = theta_hists\n",
    "        r_width = 1/self.NH\n",
    "        theta_width = 2*np.pi/self.NH\n",
    "        \n",
    "        \n",
    "        x = np.asarray(self.E_array).real\n",
    "        y = np.asarray(self.E_array).imag\n",
    "        plt.scatter(x,y)\n",
    "        plt.grid()\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('scatter plot of the eigenstates')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = np.asarray(self.z_k).real\n",
    "        y = np.asarray(self.z_k).imag\n",
    "        plt.scatter(x,y)\n",
    "        plt.grid()\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('scatter plot of z_k')\n",
    "        plt.show()\n",
    "    \n",
    "        plt.bar(r_array,r_hists,\n",
    "        width=r_width,\n",
    "        align='edge',\n",
    "        edgecolor='black',\n",
    "           color = 'orange')\n",
    "        plt.xlim(0,1)\n",
    "        plt.xlabel('|z|')\n",
    "        plt.ylabel('density')\n",
    "        if self.save_boolean:\n",
    "            plt.gcf().tight_layout()\n",
    "            plt.savefig(self.graph_path_r+'.png',dpi=250)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.bar(theta_array,theta_hists,\n",
    "        width=theta_width,\n",
    "        align='edge',\n",
    "        edgecolor='black',\n",
    "           color = 'orange')\n",
    "        plt.xlim(-np.pi,np.pi)\n",
    "        plt.xlabel('arg|z|')\n",
    "        plt.ylabel('density')\n",
    "        if self.save_boolean:\n",
    "            plt.gcf().tight_layout()\n",
    "            plt.savefig(self.graph_path_theta+'.png',dpi=250)\n",
    "        plt.show()\n",
    "        \n",
    "     \n",
    "        ##plotting a seaborn heatnap\n",
    "        df = pd.DataFrame(data=heatmap_vals,index = np.round(-imag_vals,1), columns=np.round(real_vals,1))\n",
    "        sns.heatmap(df)\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('z_k')\n",
    "        if self.save_boolean:\n",
    "            plt.gcf().tight_layout()\n",
    "            \n",
    "            plt.savefig(self.heatmap_path+'.png',dpi=250)\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def single_number_signatures(self,z_k):\n",
    "        theta = np.angle(z_k)\n",
    "        cos_theta = np.cos(theta)\n",
    "        mean_cos = np.mean(cos_theta)\n",
    "        mean_theta = np.mean(theta)\n",
    "        r = np.abs(z_k)\n",
    "        mean_r = np.mean(r)\n",
    "        return mean_r, mean_cos, mean_theta\n",
    "    \n",
    "\n",
    "method = lindbladian_Louville_operator(N=6,\n",
    "                                       h=0,\n",
    "                                       J=1,\n",
    "                                       J_prime=1,\n",
    "                                       delta=0.5,\n",
    "                                       delta_prime=1.5,\n",
    "                                       b=0,\n",
    "                                       t=0.4,tau=1,nv=65,NH=30,\n",
    "                                       M_choice=4,\n",
    "                                       gamma0=0,\n",
    "                                       gamma_L_plus=0.5,\n",
    "                                       gamma_L_min=0.3,\n",
    "                                       gamma_R_plus=0.3,\n",
    "                                       gamma_R_min=0.9,\n",
    "                                       N_L = 4,\n",
    "                                       g = 100,\n",
    "                                       r=2,\n",
    "                                       t_min=-10,t_max=10,\n",
    "                                       s_min=-10,s_max=10,\n",
    "                                       res=80,av_num=80,\n",
    "                                       n=256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method.factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "every entry is a random complex number for a matrix,\n",
    "potentially average over to\n",
    "check if it gives figure 1c, \n",
    "\n",
    "look at paper for specific (gaussian distribution)\n",
    "(non hermitian)\n",
    "\n",
    "Use random Louvillian (5th model)\n",
    "\n",
    "this has an added simplification of no symmetries so there \n",
    "isnt any projection needed.\n",
    "\n",
    "-Could do floquet version of this, so this is very \n",
    "important to check\n",
    "\n",
    "Do check with the projection function.\n",
    "\n",
    "\n",
    "Spectral statistics of non-Hermitian matrices and dissipative quantum chaos\n",
    "\n",
    "\n",
    "\n",
    "set symmetry of the hamiltonian to be block diagonal but \n",
    "dont set the jump operators to have this \n",
    "so it doesnt intefere \n",
    "\n",
    "In unitary case:\n",
    "    Form factor K(t)\n",
    "    Random unitary matrix, U[N x N] \n",
    "    and diagonalise it,\n",
    "    everything is a phase.\n",
    "    The K(t) has a universal form (figure 2 in the spectral form factor)\n",
    "    and it flattens out at t=N\n",
    "    when you put in symmetries, the thouless time,\n",
    "    which tells you something about diffusion.\n",
    "    The conserved quantity and conservation law (current conservation)\n",
    "    where j (current) is a gradient, which leads to \n",
    "    a diffusion equation. So diffusion is a \n",
    "    statement of conservation. hydrodynamics?\n",
    "    what kinds of hamiltionians give rise to hydrodynamics.\n",
    "    When a particle diffuses it takes a certain time to go \n",
    "    a certain distance (d^2 prop to t)\n",
    "    in QM, t relates to energy scale. \n",
    "    If theres a conservation law theres a dip (see picture)\n",
    "    at the thouless time, and then it goes to linear relation.\n",
    "    This is all in unitary case.\n",
    "IN dissipative case:\n",
    "    Should be the same? \n",
    "    \n",
    "    Look at the paper he put on chat, we want to try the same method with \n",
    "    random Louvillian (with Hamilitian symmetries)\n",
    "    \n",
    "\n",
    "First:\n",
    "    Calculate K(t) for unitary case, then for dissipative case.\n",
    "    Try to recreate spectral form factor of dissipative system,\n",
    "    then put some symmetries into H,\n",
    "    and then maybe put symmetries into jump operators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "method.inputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
