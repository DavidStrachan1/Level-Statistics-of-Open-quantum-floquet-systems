{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qutip import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy\n",
    "from scipy.linalg import expm\n",
    "import scipy.constants as sc\n",
    "from tqdm import tqdm_notebook\n",
    "from scipy.fft import fft,ifft,fftfreq, dct, idct\n",
    "from itertools import combinations\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from objsize import get_deep_size\n",
    "from scipy import linalg\n",
    "import datetime\n",
    "import os\n",
    "from scipy.sparse import csc_matrix\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "import scipy.special as ss\n",
    "\n",
    "\n",
    "def parallelise_job(function,inputs,verbose = 1,backend = 'loky',n_jobs = -1):\n",
    "    \"\"\"\n",
    "    Performs a parallelised task using joblib (which works in notebooks).\n",
    "    \"\"\"\n",
    "    from joblib import Parallel, delayed\n",
    "    return Parallel(n_jobs=n_jobs, verbose=verbose,backend = backend)(\n",
    "                 map(delayed(function), inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def para_projection(M_index):\n",
    "\n",
    "        ##M_indices is the list of rows/columns of\n",
    "        ##the whole space matrix representation that\n",
    "        ##have the quantum number M\n",
    "\n",
    "        ##A and B are matrices that have dimensions of 2^N by 2^N\n",
    "\n",
    "        dim_M = np.size(M_indices)\n",
    "        dim_A = A.shape[0]\n",
    "        ##out is a matrix of zeros that has dimensions of the subspace.\n",
    "        out = np.zeros(dim_M,dtype=np.complex64)\n",
    "        m=0\n",
    "        R_i = np.floor(M_index/dim_A)\n",
    "        K_i = M_index -dim_A*R_i\n",
    "        for j in M_indices:\n",
    "            R_j = np.floor(j/dim_A)\n",
    "            K_j = j -dim_A*R_j\n",
    "            A_cross_B_ij = A[R_i,R_j]*B[K_i,K_j]\n",
    "            out[m] = A_cross_B_ij\n",
    "            m +=1\n",
    "        return Qobj(out)\n",
    "M_indices = method.M_indices\n",
    "A = method.L\n",
    "B = method.L\n",
    "parallelise_job(para_projection,M_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#IS THIS ACTUALLY DIAGONAL ALWAYS?\n",
    "# self.S_z_tot = sum(self.sz_list)\n",
    "# self.S_z_super = tensor(self.S_z_tot,self.identity) - tensor(self.identity,self.S_z_tot.trans())\n",
    "\n",
    "# ##M_indices gives the columns/rows of the matrix representation of the basis\n",
    "# ##that have M=M_choice\n",
    "# self.M_indices = np.where(self.S_z_super.diag()==(self.N-self.M_choice))[0]\n",
    "\n",
    "##list of dummy indices for parallelisation\n",
    "#self.y = range(len(self.M_indices))\n",
    "##inputs for parallelisation of projection\n",
    "#self.inputs = [(self.M_indices[i],self.y[i]) for i in range(len(self.y))]\n",
    "\n",
    "##defines the dimension of the M spin subspace\n",
    "#self.dim_M = np.size(self.M_indices)\n",
    "#if self.dim_M != ss.comb(2*self.N,self.M_choice):\n",
    "  #  raise AttributeError('Size of matrix is not 2N choose M') \n",
    "print(method.dim_M)\n",
    "print(method.M_choice)\n",
    "print(method.N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "method.initialise_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(method.L)\n",
    "# print(method.S_z_super)\n",
    "#method.L*method.S_z_super - method.S_z_super*method.L\n",
    "print(method.N)\n",
    "print(method.M_choice)\n",
    "np.sum(method.S_z_super.diag()==-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next-to-nearest-neighbour-Heisenberg XXZ Hamiltonian?1\n",
      "Which Model? Deph = 0, Heisenberg XXX = 1, non H XXX = 2, no specific model=32\n",
      "Variables initialised,calculating the Louvillian.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   16.9s\n"
     ]
    }
   ],
   "source": [
    "class lindbladian_Louville_operator():\n",
    "    def __init__(self,N,h,J,J_prime,delta,delta_prime,b,t,tau,nv,NH,M_choice,\n",
    "                gamma0,gamma_L_plus,gamma_L_min,gamma_R_plus,gamma_R_min):\n",
    "        \n",
    "        for local in locals().copy(): \n",
    "            ## equivalent of writing self.gamma = gamma,self.b = b etc.\n",
    "            ## without having to rewrite it.\n",
    "            exec('self.' + local +  ' = locals()[local]')\n",
    "        \n",
    "        \n",
    "        self.model_bool = int(input('Next-to-nearest-neighbour-Heisenberg XXZ Hamiltonian?'))\n",
    "        self.model_choice = int(input('Which Model? Deph = 0, Heisenberg XXX = 1, non H XXX = 2, no specific model=3'))\n",
    "        \n",
    "        \n",
    "        ###initialising variables so they don't have to called in \n",
    "        ###each function\n",
    "        self.initialise_variables()\n",
    "        print(\"Variables initialised,calculating the Louvillian.\")\n",
    "        \n",
    "        ##calls function to create the Liouvillian\n",
    "        self.L = self.L()\n",
    "        print(\"Calculating P, the time evolution matrix.\")\n",
    "        \n",
    "        ##calls function to create P and solve for the eigenenergies.\n",
    "        self.P,self.evecs,self.evals = self.P()\n",
    "        \n",
    "        ##calls function to create z_k along with the degeneracy factor of each ratio\n",
    "        self.deg_factor = np.unique(self.evals,return_counts=True)[-1]\n",
    "        deg_bool = int(input('Remove degeneracy?'))\n",
    "        if deg_bool:\n",
    "            \n",
    "            self.E_array,self.deg_factor = np.unique(self.evals,return_counts=True)\n",
    "        else:   \n",
    "            \n",
    "            ##defining E_array for z_k_spec and for the parallelization\n",
    "            self.E_array = self.evals#np.unique(self.evals)\n",
    "        \n",
    "        \"\"\"Currently using the non-parallelised z_k function.\"\"\"\n",
    "        #self.z_k = parallelise_job(self.z_k_spec,self.E_array,verbose = False)\n",
    "        self.z_k = self.z_k(self.E_array)\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##choice of whether to save data\n",
    "        self.save_boolean = bool(int(input('Save Data?')))\n",
    "        self.add_to_average = int(input('Add to average?'))\n",
    "        \n",
    "        ##defines path for my computer\n",
    "        self.path = 'C://Users/david/OneDrive/Documents/UNI/UCL project/data/'  \n",
    "    \n",
    "        ##retrieves the single number signatures of the data and prints them.\n",
    "        self.mean_r, self.mean_cos, self.mean_theta = self.single_number_signatures(self.z_k)\n",
    "        print('mean r value = '+ str(self.mean_r))\n",
    "        print('mean cos(theta) = '+str(self.mean_cos))\n",
    "        print('mean theta = '+str(self.mean_theta))\n",
    "        \n",
    "        \n",
    "        ##list of all parameters needed\n",
    "        data_list = ['mean_r='+str(self.mean_r),\n",
    "                     'mean_cos='+str(self.mean_cos),\n",
    "                     'mean_theta='+str(self.mean_theta),\n",
    "                     'N='+str(self.N),'h='+str(self.h),\n",
    "                     'J='+str(self.J),'J_prime='+str(self.J_prime),\n",
    "                     'delta='+str(self.delta),\n",
    "                     'delta_prime='+str(self.delta),'b='+str(self.b),\n",
    "                     't='+str(self.t),'tau='+str(self.tau),\n",
    "                     'nv='+str(self.nv),'gamma0='+str(self.gamma0),\n",
    "                     'gamma_L_plus='+str(self.gamma_L_plus),\n",
    "                     'gamma_L_min='+str(self.gamma_L_min),\n",
    "                     'gamma_R_plus='+str(self.gamma_R_plus),\n",
    "                     'gamma_R_min='+str(self.gamma_R_min)]\n",
    "        ##as array\n",
    "        data_array = np.asarray((self.mean_r,self.mean_cos,\n",
    "                     self.mean_theta,self.N,self.h,\n",
    "                     self.J,self.J_prime,self.delta,self.delta_prime,\n",
    "                     self.b,self.t,self.tau,\n",
    "                     self.nv,self.gamma0,self.gamma_L_plus,\n",
    "                     self.gamma_L_min,self.gamma_R_plus,\n",
    "                     self.gamma_R_min))\n",
    "        \n",
    "        if self.save_boolean:\n",
    "            ##sorting names\n",
    "            list_name = 'list, N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "            array_name = 'array, N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "            \n",
    "            \n",
    "            ##sorting paths \n",
    "            self.SNS_path = self.path +'Single Number Signatures/'\n",
    "            self.z_k_path =self.path + 'z_k raw data/'\n",
    "            \n",
    "            \n",
    "            ##Sorting where to save the data\n",
    "            self.z_k_path_final = self.z_k_path\n",
    "            ##Deph model\n",
    "            if self.model_choice==0:\n",
    "                self.z_k_path_final = self.z_k_path+'Deph/'\n",
    "                self.SNS_path = self.SNS_path+'Deph/'\n",
    "                \n",
    "                ##needed for add_to_average function\n",
    "                average_path_add_on = ', Deph average.npy'\n",
    "                \n",
    "            ##Heisenberg model\n",
    "            if self.model_choice==1:\n",
    "                self.z_k_path_final = self.z_k_path+'Heisenberg XXX/'\n",
    "                self.SNS_path = self.SNS_path+'Heisenberg XXX/'\n",
    "                \n",
    "                ##needed for add_to_average function\n",
    "                average_path_add_on = ', Heisenberg XXX average.npy'\n",
    "                \n",
    "            ##non-Heisenberg XXX model\n",
    "            if self.model_choice==2:\n",
    "                self.z_k_path_final = self.z_k_path+'non H XXX/'\n",
    "                self.SNS_path = self.SNS_path+'non H XXX/'\n",
    "                \n",
    "                ##needed for add_to_average function\n",
    "                average_path_add_on = ', non H XXX average.npy'\n",
    "        \n",
    "            \n",
    "            if not os.path.isdir(self.z_k_path):\n",
    "                os.mkdir(self.z_k_path)\n",
    "            if not os.path.isdir(self.SNS_path):\n",
    "                os.mkdir(self.SNS_path)\n",
    "                \n",
    "            self.list_path = self.SNS_path+list_name\n",
    "            self.array_path = self.SNS_path+array_name\n",
    "            \n",
    "            \n",
    "            if self.add_to_average:\n",
    "                ##calls function to average data with all previous relevant simulations \n",
    "                self.averaging_data(self.model_choice,self.z_k_path,data_list=data_list,average_path_add_on=average_path_add_on)\n",
    "      \n",
    "            ##pathways for graphs\n",
    "            self.graph_path_r = self.z_k_path_final+'r barchart , N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "            self.graph_path_theta = self.z_k_path_final+'theta barchart , N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "            self.heatmap_path = self.z_k_path_final+'heatmap, N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "            \n",
    "            self.z_k_path_final = self.z_k_path_final+'z_k, N = '+str(self.N) + ', h = '+str(self.h) +', ' +str(datetime.datetime.today().date())\n",
    "            \n",
    "            \n",
    "            np.save(self.z_k_path_final+'.npy',self.z_k)\n",
    "            np.save(self.list_path+'.npy',data_list)\n",
    "            np.save(self.array_path+'.npy',data_array)\n",
    "        \n",
    "        ##plots data\n",
    "        self.heatmap(self.z_k,self.deg_factor)\n",
    "        print('mean r value = '+ str(self.mean_r))\n",
    "        print('mean cos(theta) = '+str(self.mean_cos))\n",
    "        print('mean theta = '+str(self.mean_theta))\n",
    "        \n",
    "    def averaging_data(self,model_choice,path,data_list,average_path_add_on):\n",
    "        \"\"\"\n",
    "        Adds the newly simulated data to the data set of all previous simulations with appropriate\n",
    "        weighting for averaging.\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        ##if the average has not been done before, the file must first be created\n",
    "        trig = int(input('First time inputing data for the average of this model?'))\n",
    "        if trig:\n",
    "                ##creates a list of size 3, with the inputs being\n",
    "                ##the data, the number of datasets added and the parameters (data_list) respectively.\n",
    "                z_k_av = [self.z_k,1,data_list]\n",
    "                np.save(path+'N=' + str(self.N) +' , b=' +str(self.b)+average_path_add_on, z_k_av)                 \n",
    "        else:\n",
    "            ##loading the average of previous simulations\n",
    "            z_k_av = np.load(path+'N=' + str(self.N) +' , b=' +str(self.b)+average_path_add_on,\n",
    "                            allow_pickle=True)\n",
    "            ##checking to see if they both have the same parameters\n",
    "            if data_list != z_k_av[-1]:\n",
    "                raise AttributeError('Trying to add two sets of data with different parameters')\n",
    "            else:\n",
    "                ##adding to the average data mathematically.\n",
    "                z_k_av_updated = []\n",
    "                z_k_av_updated.append((z_k_av[1]*z_k_av[0] + self.z_k)/(z_k_av[1]+1))\n",
    "                z_k_av_updated.append(z_k_av[1]+1)\n",
    "                z_k_av_updated.append(data_list)\n",
    "\n",
    "                np.save(path+'N=' + str(self.N) +' , b=' +str(self.b)+average_path_add_on, z_k_av_updated)\n",
    "       \n",
    "\n",
    "    def initialise_variables(self,):\n",
    "        \"\"\"\n",
    "        Defines all generic variables that are needed for the simulation.\n",
    "        \"\"\"\n",
    "\n",
    "        ####gamma is an array of 5 constants that control the dissipation \n",
    "\n",
    "        si = qeye(2) #identity for a spin-1/2 particle\n",
    "        sz = sigmaz() ## z pauli matrix\n",
    "        sx = sigmax() ## y pauli matrix\n",
    "        sy = sigmay() ## y pauli matrix\n",
    "        sigp = sigmap() ##plus ladder operator for spin 1/2\n",
    "        sigm = sigmam() ##minus ladder operator for spin 1/2\n",
    "        self.sz_list = []\n",
    "        sx_list = []\n",
    "        sy_list = []\n",
    "        sigp_list = []\n",
    "        sigm_list = []\n",
    "        h_arr = np.random.uniform(-self.h,self.h,self.N) ##random uniform distribution from -h to h\n",
    "\n",
    "        for n in range(self.N):\n",
    "            op_list = []\n",
    "            for m in range(self.N):\n",
    "                op_list.append(si) ##creates a list of identity operators for each particle\n",
    "            self.identity = tensor(op_list) ##creates an identity over the 2^N x 2^N space\n",
    "            \n",
    "            \n",
    "            op_list[n] = sz\n",
    "            self.sz_list.append(tensor(op_list))\n",
    "\n",
    "            op_list[n] = sx\n",
    "            sx_list.append(tensor(op_list))\n",
    "            \n",
    "            op_list[n] = sy\n",
    "            sy_list.append(tensor(op_list))\n",
    "            \n",
    "            if n==0:\n",
    "                op_list[n] = sigp\n",
    "                sigp_list.append(tensor(op_list))\n",
    "\n",
    "                op_list[n] = sigm\n",
    "                sigm_list.append(tensor(op_list))\n",
    "            if n==self.N-1:\n",
    "                op_list[n] = sigp\n",
    "                sigp_list.append(tensor(op_list))\n",
    "\n",
    "                op_list[n] = sigm\n",
    "                sigm_list.append(tensor(op_list))\n",
    "\n",
    "        \n",
    "        \n",
    "        self.S_z_tot = sum(self.sz_list)\n",
    "        self.S_z_super = tensor(self.S_z_tot,self.identity) - tensor(self.identity,self.S_z_tot.trans())\n",
    "        \n",
    "        ##M_indices gives the columns/rows of the matrix representation of the basis\n",
    "        ##that have M=M_choice\n",
    "        \"\"\"Note that the eigenvalues of S_z_super are given by 2(N-M) rather than (N-M). This is because when \n",
    "        a spin is flipped the change in eigenvalue is 2 (in this representation |s_l|=1, not 1/2)\"\"\"\n",
    "        self.M_indices = np.where(self.S_z_super.diag()==(2*self.N-2*self.M_choice))[0]\n",
    "         \n",
    "        ##list of dummy indices for parallelisation\n",
    "        self.y = range(len(self.M_indices))\n",
    "        \n",
    "        ##inputs for parallelisation of projection\n",
    "        self.inputs = [(self.M_indices[i],self.y[i]) for i in range(len(self.y))]\n",
    "        \n",
    "        ##defines the dimension of the M spin subspace\n",
    "        self.dim_M = np.size(self.M_indices)\n",
    "        if self.dim_M != ss.comb(2*self.N,self.M_choice):\n",
    "            raise AttributeError('Size of matrix is not 2N choose M') \n",
    "        \n",
    "        ## construct the hamiltonian \n",
    "        H_S = 0\n",
    "        self.Hk = 0\n",
    "        ## bulk dephasing\n",
    "        W_list = [] ##list of jump operators\n",
    "\n",
    "        # energy splitting terms\n",
    "        for n in range(self.N):\n",
    "            \n",
    "            ##random field term\n",
    "            H_S += h_arr[n] * self.sz_list[n]\n",
    "            ##bulk dephasing\n",
    "            W_list.append(np.sqrt(self.gamma0) * self.sz_list[n])\n",
    "            ##kicking term\n",
    "            self.Hk += self.b * sx_list[n]\n",
    "            \n",
    "\n",
    "        # interaction terms\n",
    "        for n in range(self.N-1): \n",
    "            H_S += self.J * self.delta * self.sz_list[n] * self.sz_list[n+1]\n",
    "            if self.model_bool:\n",
    "                H_S += self.J * sx_list[n] * sx_list[n+1]\n",
    "                H_S += self.J * sy_list[n] * sy_list[n+1]\n",
    "            \n",
    "        if self.model_bool:\n",
    "            for n in range(self.N-2): \n",
    "                H_S += self.J_prime * self.delta_prime * self.sz_list[n] * self.sz_list[n+2]\n",
    "                H_S += self.J_prime * sx_list[n] * sx_list[n+2]\n",
    "                H_S += self.J_prime * sy_list[n] * sy_list[n+2]\n",
    "                \n",
    "        self.H1 =H_S\n",
    "        self.dim_H = self.H1.shape[0]\n",
    "\n",
    "        ##amplitude damping\n",
    "        W_list.append(np.sqrt(self.gamma_L_plus)*sigp_list[0]) ##W_{N+1}\n",
    "        W_list.append(np.sqrt(self.gamma_L_min)*sigm_list[0]) ##W_{N+2}\n",
    "        W_list.append(np.sqrt(self.gamma_R_plus)*sigp_list[1]) ##W_{N+3}\n",
    "        W_list.append(np.sqrt(self.gamma_R_min)*sigm_list[1]) ##W_{N+4}\n",
    "        \n",
    "        self.W_list = W_list\n",
    "        self.sigp_list = sigp_list\n",
    "        self.sigm_list = sigm_list\n",
    "\n",
    "    \n",
    "    def spin_proj(self,matrix,M_choice):\n",
    "        \"\"\"\n",
    "        Takes a matrix in the whole hilbert space and projects to the M_choice subspace.\n",
    "        This function is inefficient as the whole matrix has to be calculated as an input, \n",
    "        this function isn't being currently used.\n",
    "        \"\"\"\n",
    "\n",
    "        #This gives the rows/columns (eigenstates) that have don't have M=M_choice\n",
    "        M_choice_indices = np.where(self.S_z_super.diag()!=M_choice)[0]\n",
    "        for i in range(np.size(M_choice_indices)):\n",
    "            ##np.delete is used to remove the rows and columns that correspond to \n",
    "            ##eigenstates that don't have the desired spin state.\n",
    "            ## the -i factor accounts for the fact that each iteration a row and column\n",
    "            ##is removed, decreasing the index by 1 each time.\n",
    "            matrix = np.delete(arr=matrix,obj=M_choice_indices[i]-i,axis=0)\n",
    "            \n",
    "            #deletes the ith column\n",
    "            matrix = np.delete(arr=matrix,obj=M_choice_indices[i]-i,axis=1)\n",
    "        return matrix\n",
    " \n",
    "    \n",
    "    def L(self,):\n",
    "        \"\"\"\n",
    "        creates L from the definition of its matrix representation, \n",
    "        equation 4.1 of the notes currently. \n",
    "        \"\"\"\n",
    "\n",
    "        \n",
    "        W_term = 0 \n",
    "        ###calculates sum_{\\mu}(W_{\\mu}^{\\dag}*W_{\\mu})\n",
    "        for i in range(len(self.W_list)):\n",
    "            W_term += (self.W_list[i].dag())*self.W_list[i]\n",
    "               \n",
    "        H_left = self.H1 - (1j/2)*W_term\n",
    "        H_right = self.H1 + (1j/2)*W_term\n",
    "\n",
    "        H_cross_term = 0\n",
    "        ##calculates  sum_{\\mu}(W_{\\mu}\\otimes W_{\\mu}^{\\dag})\n",
    "        for i in range(len(self.W_list)):\n",
    "            self.A = self.W_list[i]\n",
    "            self.dim_A = self.A.shape[0]\n",
    "            self.B = self.W_list[i].conj()\n",
    "            #H_cross_term += self.projection(self.M_indices)\n",
    "        \n",
    "            outputs = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "            output = np.column_stack([outputs[i] for i in self.y])\n",
    "            H_cross_term += output\n",
    "            \n",
    "        self.A = H_left\n",
    "        self.B = self.identity\n",
    "        outputs = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "        L = -1j*np.column_stack([outputs[i] for i in self.y])\n",
    "    \n",
    "        \n",
    "        self.A = self.identity\n",
    "        self.B = H_right.trans()\n",
    "        outputs = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "        L += 1j*np.column_stack([outputs[i] for i in self.y])\n",
    "        \n",
    "        L += H_cross_term\n",
    "        return Qobj(L)\n",
    "    \n",
    "    def P(self,):\n",
    "        \n",
    "        if self.t>(self.tau/2):\n",
    "            ##defining the commutator kicking superoperator\n",
    "            self.A = self.Hk\n",
    "            self.dim_A = self.A.shape[0]\n",
    "            self.B = self.identity\n",
    "            HK_commute_SO = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "            HK_commute_SO = -1j*np.column_stack([outputs[i] for i in self.y])\n",
    "            \n",
    "            self.A = self.identity\n",
    "            self.B = self.Hk.trans()\n",
    "            output = dict(parallelise_job(self.para_projection,self.inputs))\n",
    "            output = 1j*np.column_stack([outputs[i] for i in self.y])\n",
    "            HK_commute_SO += output\n",
    "            \n",
    "        \n",
    "        ###exponentiates the matrices and calculates P\n",
    "            expH = Qobj(HK_commute_SO).expm()\n",
    "            exp1 = (self.L*self.tau/2).expm()\n",
    "            exp2 = (self.L*(self.t-self.tau/2)).expm()\n",
    "            P = exp2*(expH*exp1)\n",
    "        if self.t<=self.tau/2:\n",
    "            P = (self.L*self.t).expm()\n",
    "        \n",
    "        evals = P.eigenstates()[0]\n",
    "        evecs = P.eigenstates()[1]\n",
    "\n",
    "        return P,evecs,evals\n",
    "    \n",
    "    def projection(self,A,B,M_indices):\n",
    "        \"\"\"\n",
    "        Calculates the columns of the whole matrix representation that give the \n",
    "        desired subspace, and only calculate them. This is the unparallelised version, which \n",
    "        isn't currently being used.\n",
    "         The loop takes the the column/row indices and calculates what element they correspond to in\n",
    "         the Kronecker product of A cross B. For explanation of the R, K terms see the latex notes.\n",
    "        \"\"\"\n",
    "\n",
    "        ##M_indices is the list of rows/columns of\n",
    "        ##the whole space matrix representation that\n",
    "        ##have the quantum number M\n",
    "\n",
    "        ##A and B are matrices that have dimensions of 2^N by 2^N\n",
    "\n",
    "        dim_M = np.size(M_indices)\n",
    "        dim_A = A.shape[0]\n",
    "        ##out is a matrix of zeros that has dimensions of the subspace.\n",
    "        out = np.zeros((dim_M,dim_M),dtype=np.complex64)\n",
    "        n=-1\n",
    "        for i in tqdm_notebook(M_indices,leave=False):\n",
    "            m = 0\n",
    "            n += 1\n",
    "            for j in M_indices:\n",
    "                R_i = np.floor(i/dim_A)\n",
    "                R_j = np.floor(j/dim_A)\n",
    "                K_i = i -dim_A*R_i\n",
    "                K_j = j -dim_A*R_j\n",
    "                #print(R_j)\n",
    "                #print(M_indices[-1])\n",
    "                #print(np.max(np.array((R_i,R_j,K_i,K_j))))\n",
    "                A_cross_B_ij = A[R_i,R_j]*B[K_i,K_j]\n",
    "                out[n,m] = A_cross_B_ij\n",
    "                m +=1\n",
    "        return Qobj(out)\n",
    "    \n",
    "    def para_projection(self,M_index_y):\n",
    "        \"\"\"\n",
    "        Parallelised version of the projection function.\n",
    "        \"\"\"\n",
    "        ##y is a list of dummy indices needed to recover the \n",
    "        ##order after parallelisation\n",
    "        M_index,y = M_index_y\n",
    "        \n",
    "\n",
    "        ##M_indices is the list of rows/columns of\n",
    "        ##the whole space matrix representation that\n",
    "        ##have the quantum number M\n",
    "\n",
    "        ##A and B are matrices that have dimensions of 2^N by 2^N\n",
    "\n",
    "        ##out is a matrix of zeros that has dimensions of the subspace.\n",
    "        out = np.zeros(self.dim_M,dtype=np.complex64)\n",
    "        m=0\n",
    "        R_i = np.floor(M_index/self.dim_A)\n",
    "        K_i = M_index -self.dim_A*R_i\n",
    "        for j in self.M_indices:\n",
    "            R_j = np.floor(j/self.dim_A)\n",
    "            K_j = j -self.dim_A*R_j\n",
    "            A_cross_B_ij = self.A[R_i,R_j]*self.B[K_i,K_j]\n",
    "            out[m] = A_cross_B_ij\n",
    "            m +=1\n",
    "        return y, Qobj(out)\n",
    "\n",
    "    \n",
    "    \n",
    "    '''''''''''''''''Level Statistics functions'''''''''''''''''\n",
    "    def z_k(self,E_array):\n",
    "        z_k = [] ##setting up ratio array\n",
    "        \n",
    "        \n",
    "        for i in tqdm_notebook(range(np.size(E_array)),leave=False):\n",
    "                \n",
    "            ##creating an array of the indices of the ratios ascending in magnitude from \n",
    "            ##the ith ratio\n",
    "            E_idx_sorted = np.argsort(np.abs(E_array-E_array[i]))\n",
    "            \n",
    "            ##takes the first one\n",
    "            NN = E_array[E_idx_sorted[1]] \n",
    "            diff1 = NN-E_array[i]\n",
    "            ##takes the second one\n",
    "            NNN = E_array[E_idx_sorted[2]] \n",
    "            diff2 = NNN-E_array[i]\n",
    "            \n",
    "            ##definition of z_k\n",
    "            z_k.append(np.nan_to_num(diff1/diff2))\n",
    "        z_k = np.asarray(z_k) \n",
    "        return z_k\n",
    "    \n",
    "    \n",
    "    def z_k_spec(self,val):\n",
    "        \n",
    "      \n",
    "        ##creating an array of the indices of the ratios ascending in magnitude from \n",
    "        ##the ith ratio\n",
    "        E_idx_sorted = np.argsort(np.abs(self.E_array-val))\n",
    "\n",
    "        ##takes the first one\n",
    "        NN = self.E_array[E_idx_sorted[1]] \n",
    "        diff1 = NN-val\n",
    "        ##takes the second one\n",
    "        NNN = self.E_array[E_idx_sorted[2]] \n",
    "        diff2 = NNN-val\n",
    "\n",
    "        ##definition of z_k\n",
    "        z_k_spec = np.nan_to_num(diff1/diff2)\n",
    "        \n",
    "        return z_k_spec\n",
    "\n",
    "    \n",
    "    def heatmap(self,z_k,deg_factor):\n",
    "        print('Setting up plots')\n",
    "        \n",
    "        ##creating grid in complex space\n",
    "        \"\"\"\n",
    "        To ensure there is an (0,0) point in both real_vals and imag_vals,\n",
    "        self.nv must be odd\n",
    "        \"\"\"\n",
    "        real_vals = np.linspace(-1,1,self.nv)\n",
    "        imag_vals = 1j*np.linspace(-1,1,self.nv)\n",
    "        \n",
    "        ##creating empty 2D array for heatmap values\n",
    "        \n",
    "        heatmap_vals = np.zeros((self.nv,self.nv))\n",
    "        \n",
    "        ##resolution of grid\n",
    "        delta = (np.max(real_vals)-np.min(real_vals))/np.size(real_vals)\n",
    "        \n",
    "        for i in tqdm_notebook(range(self.nv-1),leave=False):\n",
    "            for j in range(self.nv-1):\n",
    "                \n",
    "                ##creates booleans in order to get rid of any values\n",
    "                ##that don't lie in the ith,jth square of the grid\n",
    "                real_bool =(z_k.real>=real_vals[i])*(z_k.real<=real_vals[i+1]) \n",
    "                imag_bool =(z_k.imag>=(imag_vals[j].imag))*(z_k.imag<=(imag_vals[j+1].imag))\n",
    "    \n",
    "                ##summing up how many non-zero values there are,\n",
    "                ##which is then multiplied by the degeneracy factor of each distinct eigenenergy.\n",
    "                \n",
    "                heatmap_vals[j,i] =  np.sum(real_bool*imag_bool)##python indices are opposite to matrix convention\n",
    "                \n",
    "                \n",
    "        ##self.NH defines the number of histograms\n",
    "        theta_array = np.linspace(-np.pi,np.pi,self.NH)\n",
    "        r_array = np.linspace(0,1,self.NH)\n",
    "        theta_hists = np.zeros(self.NH)\n",
    "        r_hists = np.zeros(self.NH)\n",
    "        \n",
    "        r_vals = np.abs(z_k)\n",
    "        theta_vals = np.angle(z_k)\n",
    "        \n",
    "        ##creates a 1D array of the heatmap values\n",
    "        flattened_vals = heatmap_vals.flatten()\n",
    "        \n",
    "        ###flattens theta values into a 1D array.\n",
    "        flattened_theta_vals = theta_vals.flatten()\n",
    "        \n",
    "        ###flattens r values into a 1D array.\n",
    "        flattened_r_vals = r_vals.flatten()\n",
    "        \n",
    "        for i in range(self.NH-1):\n",
    "            r_bool =(flattened_r_vals>=r_array[i])*(flattened_r_vals<=r_array[i+1]) \n",
    "            theta_bool =(flattened_theta_vals>=theta_array[i])*(flattened_theta_vals<=theta_array[i+1])\n",
    "            r_hists[i] = np.sum(r_bool)/np.size(z_k)\n",
    "            theta_hists[i] = np.sum(theta_bool)/np.size(z_k)\n",
    "        \n",
    "        \n",
    "        ##making the local variables global (just so debugging is easier)\n",
    "        self.r_array = r_array\n",
    "        self.r_hists = r_hists\n",
    "        self.theta_array = theta_array\n",
    "        self.theta_hists = theta_hists\n",
    "        r_width = 1/self.NH\n",
    "        theta_width = 2*np.pi/self.NH\n",
    "        \n",
    "        \n",
    "        x = np.asarray(self.E_array).real\n",
    "        y = np.asarray(self.E_array).imag\n",
    "        plt.scatter(x,y)\n",
    "        plt.grid()\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('scatter plot of the eigenstates')\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = np.asarray(self.z_k).real\n",
    "        y = np.asarray(self.z_k).imag\n",
    "        plt.scatter(x,y)\n",
    "        plt.grid()\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('scatter plot of z_k')\n",
    "        plt.show()\n",
    "    \n",
    "        plt.bar(r_array,r_hists,\n",
    "        width=r_width,\n",
    "        align='edge',\n",
    "        edgecolor='black',\n",
    "           color = 'orange')\n",
    "        plt.xlim(0,1)\n",
    "        plt.xlabel('|z|')\n",
    "        plt.ylabel('density')\n",
    "        if self.save_boolean:\n",
    "            plt.gcf().tight_layout()\n",
    "            plt.savefig(self.graph_path_r+'.png',dpi=250)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.bar(theta_array,theta_hists,\n",
    "        width=theta_width,\n",
    "        align='edge',\n",
    "        edgecolor='black',\n",
    "           color = 'orange')\n",
    "        plt.xlim(-np.pi,np.pi)\n",
    "        plt.xlabel('arg|z|')\n",
    "        plt.ylabel('density')\n",
    "        if self.save_boolean:\n",
    "            plt.gcf().tight_layout()\n",
    "            plt.savefig(self.graph_path_theta+'.png',dpi=250)\n",
    "        plt.show()\n",
    "        \n",
    "     \n",
    "        ##plotting a seaborn heatnap\n",
    "        df = pd.DataFrame(data=heatmap_vals,index = np.round(-imag_vals,1), columns=np.round(real_vals,1))\n",
    "        sns.heatmap(df)\n",
    "        plt.xlabel('real axis')\n",
    "        plt.ylabel('imaginary axis')\n",
    "        plt.title('z_k')\n",
    "        if self.save_boolean:\n",
    "            plt.gcf().tight_layout()\n",
    "            \n",
    "            plt.savefig(self.heatmap_path+'.png',dpi=250)\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    def single_number_signatures(self,z_k):\n",
    "        theta = np.angle(z_k)\n",
    "        cos_theta = np.cos(theta)\n",
    "        mean_cos = np.mean(cos_theta)\n",
    "        mean_theta = np.mean(theta)\n",
    "        r = np.abs(z_k)\n",
    "        mean_r = np.mean(r)\n",
    "        return mean_r, mean_cos, mean_theta\n",
    "    \n",
    "\n",
    "method = lindbladian_Louville_operator(N=8,\n",
    "                                       h=0,\n",
    "                                       J=1,\n",
    "                                       J_prime=0,\n",
    "                                       delta=1,\n",
    "                                       delta_prime=0,\n",
    "                                       b=0,\n",
    "                                       t=0.3,tau=1,nv=65,NH=30,\n",
    "                                       M_choice=9,\n",
    "                                       gamma0=0,\n",
    "                                       gamma_L_plus=0.5,\n",
    "                                       gamma_L_min=0.3,\n",
    "                                       gamma_R_plus=0.3,\n",
    "                                       gamma_R_min=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DO L AND S SUPER ALWAYS COMMUTE?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  2., ..., -2., -2.,  0.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method.S_z_super.diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16384"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "4**7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-71-f02e73c2d568>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-71-f02e73c2d568>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    chunksize=100,)\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
